import os
import base64
import tempfile
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from openai import OpenAI
from elevenlabs import generate, Voice, VoiceSettings, set_api_key
from docxtpl import DocxTemplate

# Set up environment
app = Flask(__name__)
CORS(app)

# âœ… Initialize APIs
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
set_api_key(os.getenv("ELEVENLABS_API_KEY"))

# âœ… Choose the best Arabic-compatible ElevenLabs voice
voice = Voice(
    voice_id="EXAVITQu4vr4xnSDxMaL",  # "Hala" voice (Arabic-compatible)
    settings=VoiceSettings(stability=0.4, similarity_boost=0.9)
)

# âœ… User session storage
user_session = {
    "current_field": "Date",
    "fields": {}
}

# âœ… Report fields and Arabic prompts
field_order = ["Date", "Briefing", "LocationObservations", "Examination", "Outcomes", "TechincalOpinion"]

field_prompts = {
    "Date": "ğŸ“… Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø®Ø¨Ø±Ù†ÙŠ Ø¨ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ù‚Ø¹Ø©.",
    "Briefing": "ğŸ“ Ù…Ø§ Ù‡Ùˆ Ù…ÙˆØ¬Ø² Ø§Ù„Ø­Ø§Ø¯Ø«ØŸ",
    "LocationObservations": "ğŸ“ ØµÙ Ù„ÙŠ Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒ Ø­ÙˆÙ„ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø­Ø§Ø¯Ø«.",
    "Examination": "ğŸ”¬ Ù…Ø§ Ù‡ÙŠ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­Øµ Ø§Ù„ÙÙ†ÙŠØŸ",
    "Outcomes": "ğŸ“Œ Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙØ­ØµØŸ",
    "TechincalOpinion": "ğŸ’¡ Ù…Ø§ Ù‡Ùˆ Ø±Ø£ÙŠÙƒ Ø§Ù„ÙÙ†ÙŠ ÙÙŠ Ø§Ù„Ø­Ø§Ø¯Ø«ØŸ"
}

field_names_ar = {
    "Date": "Ø§Ù„ØªØ§Ø±ÙŠØ®",
    "Briefing": "Ù…ÙˆØ¬Ø² Ø§Ù„ÙˆØ§Ù‚Ø¹Ø©",
    "LocationObservations": "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù…ÙˆÙ‚Ø¹",
    "Examination": "Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙØ­Øµ Ø§Ù„ÙÙ†ÙŠ",
    "Outcomes": "Ø§Ù„Ù†ØªÙŠØ¬Ø©",
    "TechincalOpinion": "Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„ÙÙ†ÙŠ"
}

# âœ… Generate voice from text using ElevenLabs
def speak_text(text):
    audio = generate(text=text, voice=voice)
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    temp_file.write(audio)
    temp_file.close()
    return temp_file.name

# âœ… Rephrase and summarize Arabic text using OpenAI
def rephrase_text(text, field):
    prompt = f"""
Ø£Ø¹Ø¯ ØµÙŠØ§ØºØ© Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù„ÙŠÙƒÙˆÙ† Ø£ÙƒØ«Ø± Ø±Ø³Ù…ÙŠØ© ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ© Ù„ØªÙ‚Ø±ÙŠØ± Ø´Ø±Ø·Ø©:

Ø§Ù„Ù†Øµ:
{text}

â€” Ø§Ù„Ø­Ù‚Ù„: {field_names_ar.get(field, field)}
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4
    )
    return response.choices[0].message.content.strip()

# âœ… Route to serve voice response
@app.route("/speak", methods=["POST"])
def handle_speak():
    data = request.json
    text = data.get("text", "")
    audio_path = speak_text(text)
    return send_file(audio_path, mimetype="audio/mpeg")

# âœ… Route to get next field prompt
@app.route("/next", methods=["GET"])
def next_prompt():
    current = user_session["current_field"]
    fields = user_session["fields"]

    if current not in fields:
        prompt = field_prompts.get(current, "ğŸ™ï¸ ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†.")
        return jsonify({"field": current, "prompt": prompt})

    current_index = field_order.index(current)
    if current_index + 1 >= len(field_order):
        return jsonify({"done": True, "message": "âœ… ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„. ÙŠØªÙ… Ø§Ù„Ø¢Ù† ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØªÙ‚Ø±ÙŠØ±..."})

    next_field = field_order[current_index + 1]
    user_session["current_field"] = next_field
    prompt = field_prompts[next_field]
    return jsonify({"field": next_field, "prompt": prompt})

# âœ… Route to submit audio transcription (replace this with real Whisper logic)
@app.route("/submit", methods=["POST"])
def submit_transcription():
    data = request.json
    text = data.get("text", "")
    field = user_session["current_field"]

    refined = rephrase_text(text, field)
    user_session["fields"][field] = refined

    return jsonify({
        "saved": True,
        "field": field,
        "value": refined
    })

# âœ… Route to generate and download Word report
@app.route("/report", methods=["GET"])
def generate_report():
    tpl = DocxTemplate("police_report_template.docx")
    tpl.render(user_session["fields"])
    output_path = "final_report.docx"
    tpl.save(output_path)
    return send_file(output_path, as_attachment=True)

# âœ… Greeting route
@app.route("/", methods=["GET"])
def greet():
    greeting_text = "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…Ø³Ø§Ø¹Ø¯ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø®Ø§Øµ Ø¨Ù‚Ø³Ù… Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠØ©. ğŸ™ï¸"
    audio_path = speak_text(greeting_text)
    return send_file(audio_path, mimetype="audio/mpeg")

if __name__ == "__main__":
    print("âœ… OpenAI version:", OpenAI.__module__)
    app.run(host="0.0.0.0", port=10000)
